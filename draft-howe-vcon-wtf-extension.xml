<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE rfc [
  <!ENTITY nbsp    "&#160;">
  <!ENTITY zwsp   "&#8203;">
  <!ENTITY nbhy   "&#8209;">
  <!ENTITY wj     "&#8288;">
]>
<?xml-stylesheet type="text/xsl" href="rfc2629.xslt" ?>
<!-- generated by https://github.com/cabo/kramdown-rfc version 1.7.29 (Ruby 3.4.6) -->
<rfc xmlns:xi="http://www.w3.org/2001/XInclude" ipr="trust200902" docName="draft-howe-vcon-wtf-extension-latest" category="std" consensus="true" tocInclude="true" sortRefs="true" symRefs="true" version="3">
  <!-- xml2rfc v2v3 conversion 3.30.2 -->
  <front>
    <title abbrev="vCon WTF Extension">vCon World Transcription Format Extension</title>
    <seriesInfo name="Internet-Draft" value="draft-howe-vcon-wtf-extension-latest"/>
    <author initials="T." surname="McCarthy-Howe" fullname="Thomas McCarthy-Howe">
      <organization>VCONIC</organization>
      <address>
        <email>ghostofbasho@gmail.com</email>
      </address>
    </author>
    <date year="2025" month="September" day="25"/>
    <area>Applications and Real-Time</area>
    <workgroup>vCon</workgroup>
    <keyword>Internet-Draft</keyword>
    <abstract>
      <?line 127?>

<t>This document defines the World Transcription Format (WTF) extension for Virtualized Conversations (vCon). The WTF extension provides a standardized method for representing speech-to-text transcription data from multiple providers within vCon containers. This extension enables consistent transcription storage, analysis, and interoperability across different transcription services while preserving provider-specific features through extensible fields.</t>
      <t>The WTF extension is designed as a Compatible Extension that introduces transcription attachments without altering existing vCon semantics, ensuring backward compatibility with existing vCon implementations.</t>
    </abstract>
    <note removeInRFC="true">
      <name>About This Document</name>
      <t>
        The latest revision of this draft can be found at <eref target="https://vcon-dev.github.io/draft-howe-vcon-wtf-extension/draft-howe-vcon-wtf-extension-latest.html"/>.
        Status information for this document may be found at <eref target="https://datatracker.ietf.org/doc/draft-howe-vcon-wtf-extension/"/>.
      </t>
      <t>
        Discussion of this document takes place on the
        vCon Working Group mailing list (<eref target="mailto:vcon@ietf.org"/>),
        which is archived at <eref target="https://mailarchive.ietf.org/arch/browse/vcon/"/>.
        Subscribe at <eref target="https://www.ietf.org/mailman/listinfo/vcon/"/>.
      </t>
      <t>Source for this draft and an issue tracker can be found at
        <eref target="https://github.com/vcon-dev/draft-howe-vcon-wtf-extension"/>.</t>
    </note>
  </front>
  <middle>
    <?line 133?>

<section anchor="requirements-language">
      <name>Requirements Language</name>
      <t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as described in BCP 14 <xref target="RFC8174">RFC2119</xref> when, and only when, they appear in all capitals, as shown here.</t>
    </section>
    <section anchor="introduction">
      <name>Introduction</name>
      <t>Virtualized Conversations (vCon) <xref target="I-D.draft-ietf-vcon-core-00"/> provide a standardized container format for conversation data, enabling interoperability across different communication platforms and modalities. As speech-to-text technology becomes increasingly important for conversation analysis, compliance, and accessibility, there is a growing need for standardized transcription representation within vCon containers.</t>
      <t>Current transcription services each use proprietary formats, making it difficult to:</t>
      <ul spacing="normal">
        <li>
          <t>Switch between transcription providers without data conversion</t>
        </li>
        <li>
          <t>Perform comparative analysis across different providers</t>
        </li>
        <li>
          <t>Maintain consistent data processing pipelines</t>
        </li>
        <li>
          <t>Preserve transcription metadata during system migrations</t>
        </li>
        <li>
          <t>Ensure long-term accessibility and archival compliance</t>
        </li>
      </ul>
      <t>This document defines the World Transcription Format (WTF) extension for vCon, which addresses these challenges by providing:</t>
      <ul spacing="normal">
        <li>
          <t>A unified schema for transcription data from any speech-to-text provider</t>
        </li>
        <li>
          <t>Hierarchical organization from words to segments to complete transcripts</t>
        </li>
        <li>
          <t>Extensible fields for provider-specific features</t>
        </li>
        <li>
          <t>Built-in quality metrics and confidence scoring</t>
        </li>
        <li>
          <t>Support for real-time and batch transcription workflows</t>
        </li>
        <li>
          <t>Consistent export capabilities to standard subtitle and caption formats</t>
        </li>
      </ul>
      <t>The WTF extension enables organizations to standardize their transcription workflows while maintaining the flexibility to use multiple providers and preserve provider-specific enhancements.</t>
    </section>
    <section anchor="conventions-and-definitions">
      <name>Conventions and Definitions</name>
      <section anchor="core-terms">
        <name>Core Terms</name>
        <t><strong>World Transcription Format (WTF)</strong>: A standardized JSON schema for representing speech-to-text transcription data from any provider in a consistent, interoperable format.</t>
        <t><strong>Transcription Provider</strong>: A service or system that converts audio or video content to text, such as Whisper(TM), Deepgram(TM), AssemblyAI(TM), Google Cloud Speech-to-Text(TM), Amazon Transcribe(TM), or Azure Speech Services(TM).</t>
        <t><strong>WTF Attachment</strong>: A vCon attachment with type "wtf_transcription" that contains structured transcription information in World Transcription Format.</t>
        <t><strong>Segment</strong>: A logical chunk of transcribed content, typically representing sentence or phrase boundaries with associated timing information.</t>
        <t><strong>Speaker Diarization</strong>: The process of partitioning an audio stream into homogeneous segments according to the speaker identity, enabling "who spoke when" analysis.</t>
        <t><strong>Compatible Extension</strong>: A vCon extension that introduces additional data without altering the meaning or structure of existing elements, as defined in <xref target="I-D.draft-ietf-vcon-core-00"/>.</t>
      </section>
    </section>
    <section anchor="world-transcription-format-overview">
      <name>World Transcription Format Overview</name>
      <t>The World Transcription Format uses a hierarchical JSON structure designed to capture transcription data at multiple levels of granularity while maintaining consistency across different providers.</t>
      <section anchor="design-principles">
        <name>Design Principles</name>
        <t><strong>Completeness</strong>: WTF captures all essential transcription data including text, timing, confidence scores, and speaker information.</t>
        <t><strong>Consistency</strong>: Provides uniform structure regardless of the underlying transcription provider.</t>
        <t><strong>Extensibility</strong>: Supports provider-specific features through structured extension fields.</t>
        <t><strong>Validation</strong>: Includes built-in data integrity checking and quality metrics.</t>
        <t><strong>Hierarchical Organization</strong>: Natural progression from words to segments to complete transcripts.</t>
      </section>
      <section anchor="core-structure">
        <name>Core Structure</name>
        <t>WTF uses a hierarchical JSON structure with three required sections and multiple optional enrichment layers:</t>
        <artwork type="json"><![CDATA[
{
  "transcript": { /* Required: Core transcript information */ },
  "segments": [ /* Required: Time-aligned text segments */ ],
  "metadata": { /* Required: Processing metadata */ },
  "words": [ /* Optional: Word-level details */ ],
  "speakers": { /* Optional: Speaker diarization */ },
  "alternatives": [ /* Optional: Alternative transcriptions */ },
  "enrichments": { /* Optional: Analysis features */ },
  "extensions": { /* Optional: Provider-specific data */ },
  "quality": { /* Optional: Quality metrics */ },
  "streaming": { /* Optional: Streaming information */ }
}
]]></artwork>
      </section>
    </section>
    <section anchor="vcon-wtf-extension-definition">
      <name>vCon WTF Extension Definition</name>
      <section anchor="extension-classification">
        <name>Extension Classification</name>
        <t>The WTF extension is a <strong>Compatible Extension</strong> as defined in Section 2.5 of <xref target="I-D.draft-ietf-vcon-core-00"/>. This extension:</t>
        <ul spacing="normal">
          <li>
            <t>Introduces transcription data without altering existing vCon semantics</t>
          </li>
          <li>
            <t>Can be safely ignored by implementations that don't support transcription processing</t>
          </li>
          <li>
            <t>Does not require listing in the <tt>must_support</tt> parameter</t>
          </li>
          <li>
            <t>Maintains backward compatibility with existing vCon implementations</t>
          </li>
        </ul>
      </section>
      <section anchor="extension-registration">
        <name>Extension Registration</name>
        <t>This document defines the "wtf_transcription" extension token for registration in the vCon Extensions Names Registry:</t>
        <ul spacing="normal">
          <li>
            <t><strong>Extension Name</strong>: wtf_transcription</t>
          </li>
          <li>
            <t><strong>Extension Description</strong>: World Transcription Format for standardized speech-to-text representation with multi-provider support</t>
          </li>
          <li>
            <t><strong>Change Controller</strong>: IESG</t>
          </li>
          <li>
            <t><strong>Specification Document</strong>: This document</t>
          </li>
        </ul>
      </section>
      <section anchor="extension-usage">
        <name>Extension Usage</name>
        <t>vCon instances that include WTF transcription attachments SHOULD include "wtf_transcription" in the <tt>extensions</tt> array:</t>
        <artwork type="json"><![CDATA[
{
  "uuid": "01234567-89ab-cdef-0123-456789abcdef",
  "extensions": ["wtf_transcription"],
  "created_at": "2025-01-02T12:00:00Z",
  "parties": [...],
  "dialog": [...],
  "attachments": [
    {
      "type": "wtf_transcription",
      "start": "2025-01-02T12:15:30Z",
      "party": 0,
      "dialog": 0,
      "encoding": "json",
      "body": {
        // WTF transcription data structure defined below
      }
    }
  ]
}
]]></artwork>
      </section>
    </section>
    <section anchor="wtf-attachment-structure">
      <name>WTF Attachment Structure</name>
      <section anchor="attachment-container">
        <name>Attachment Container</name>
        <t>Transcription information MUST be included as vCon attachments using the standard attachment object structure defined in Section 4.4 of <xref target="I-D.draft-ietf-vcon-core-00"/>.</t>
        <t>The WTF transcription attachment MUST include:</t>
        <ul spacing="normal">
          <li>
            <t><strong>type</strong>: MUST be set to "wtf_transcription"</t>
          </li>
          <li>
            <t><strong>encoding</strong>: MUST be set to "json" for structured transcription data</t>
          </li>
          <li>
            <t><strong>body</strong>: MUST contain the WTF transcription data structure as defined below</t>
          </li>
        </ul>
        <t>The WTF transcription attachment SHOULD include:</t>
        <ul spacing="normal">
          <li>
            <t><strong>start</strong>: ISO 8601 timestamp when transcription was created</t>
          </li>
          <li>
            <t><strong>party</strong>: Index of the party in the vCon parties array (for single-speaker transcription)</t>
          </li>
          <li>
            <t><strong>dialog</strong>: Index of the associated dialog in the vCon dialog array</t>
          </li>
        </ul>
      </section>
      <section anchor="wtf-body-structure">
        <name>WTF Body Structure</name>
        <t>The <tt>body</tt> field of the WTF transcription attachment MUST contain a JSON object with the following structure:</t>
        <section anchor="required-fields">
          <name>Required Fields</name>
          <section anchor="transcript-object">
            <name>Transcript Object</name>
            <artwork type="json"><![CDATA[
"transcript": {
  "text": "string",       // Complete transcription text
  "language": "string",   // BCP-47 language code (e.g., "en-US")
  "duration": "number",   // Total audio duration in seconds
  "confidence": "number"  // Overall confidence score \[0.0-1.0\]
}
]]></artwork>
            <t>The transcript object provides the high-level summary of the entire transcription:</t>
            <ul spacing="normal">
              <li>
                <t><strong>text</strong>: The complete, concatenated transcription text</t>
              </li>
              <li>
                <t><strong>language</strong>: MUST use BCP-47 format <xref target="BCP47"/> (examples: "en-US", "es-MX", "fr-CA")</t>
              </li>
              <li>
                <t><strong>duration</strong>: Floating-point seconds, MUST be &gt;= 0</t>
              </li>
              <li>
                <t><strong>confidence</strong>: Normalized to <tt>[0, 1]</tt> range regardless of provider scale</t>
              </li>
            </ul>
          </section>
          <section anchor="segments-array">
            <name>Segments Array</name>
            <artwork type="json"><![CDATA[
"segments": [
  {
    "id": "integer",              // Sequential segment identifier
    "start": "number",            // Start time in seconds
    "end": "number",              // End time in seconds
    "text": "string",             // Segment text content
    "confidence": "number",       // Segment-level confidence \[0.0-1.0\]
    "speaker": "integer|string",  // Optional: Speaker identifier
    "words": ["integer"]          // Optional: Array of word indices
  }
]
]]></artwork>
            <t>Segments represent logical chunks of transcribed content, typically sentence or phrase boundaries:</t>
            <ul spacing="normal">
              <li>
                <t><strong>id</strong>: MUST be unique within the document, typically sequential</t>
              </li>
              <li>
                <t><strong>start</strong>/<strong>end</strong>: Floating-point seconds, where end &gt; start</t>
              </li>
              <li>
                <t><strong>text</strong>: SHOULD be trimmed of leading/trailing whitespace</t>
              </li>
              <li>
                <t><strong>speaker</strong>: Can be integer (<tt>0</tt>, <tt>1</tt>, <tt>2</tt>) or string ("Speaker A")</t>
              </li>
              <li>
                <t><strong>words</strong>: References indices in the words array</t>
              </li>
            </ul>
          </section>
          <section anchor="metadata-object">
            <name>Metadata Object</name>
            <artwork type="json"><![CDATA[
"metadata": {
  "created_at": "string",        // ISO 8601 timestamp
  "processed_at": "string",      // ISO 8601 timestamp
  "provider": "string",          // Provider name (lowercase)
  "model": "string",             // Model/version identifier
  "processing_time": "number",   // Optional: Processing duration in seconds
  "audio": {
    "duration": "number",        // Source audio duration in seconds
    "sample_rate": "integer",    // Optional: Sample rate in Hz
    "channels": "integer",       // Optional: Number of channels
    "format": "string",          // Optional: Audio format
    "bitrate": "integer"         // Optional: Bitrate in kbps
  },
  "options": "object"            // Provider-specific options used
}
]]></artwork>
            <t>The metadata object captures processing and source information:</t>
            <ul spacing="normal">
              <li>
                <t><strong>created_at</strong>/<strong>processed_at</strong>: MUST use ISO 8601 format</t>
              </li>
              <li>
                <t><strong>provider</strong>: Lowercase identifier for supported providers</t>
              </li>
              <li>
                <t><strong>model</strong>: Provider's model identifier (e.g., "whisper-large-v3", "nova-2")</t>
              </li>
              <li>
                <t><strong>options</strong>: Preserves provider-specific configuration</t>
              </li>
            </ul>
          </section>
        </section>
        <section anchor="optional-fields">
          <name>Optional Fields</name>
          <section anchor="words-array">
            <name>Words Array</name>
            <artwork type="json"><![CDATA[
"words": [
  {
    "id": "integer",              // Sequential word identifier
    "start": "number",            // Word start time in seconds
    "end": "number",              // Word end time in seconds
    "text": "string",             // Word text
    "confidence": "number",       // Word-level confidence \[0.0-1.0\]
    "speaker": "integer|string",  // Optional: Speaker identifier
    "is_punctuation": "boolean"   // Optional: Punctuation marker
  }
]
]]></artwork>
          </section>
          <section anchor="speakers-object">
            <name>Speakers Object</name>
            <artwork type="json"><![CDATA[
"speakers": {
  "speaker_id": {
    "id": "integer|string",       // Speaker identifier
    "label": "string",            // Human-readable speaker name
    "segments": ["integer"],      // Array of segment IDs for this speaker
    "total_time": "number",       // Total speaking time in seconds
    "confidence": "number"        // Diarization confidence \[0.0-1.0\]
  }
}
]]></artwork>
          </section>
          <section anchor="quality-object">
            <name>Quality Object</name>
            <artwork type="json"><![CDATA[
"quality": {
  "audio_quality": "string",      // high, medium, low
  "background_noise": "number",   // Noise level \[0.0-1.0\]
  "multiple_speakers": "boolean",
  "overlapping_speech": "boolean",
  "silence_ratio": "number",      // Percentage of silence
  "average_confidence": "number",
  "low_confidence_words": "integer",
  "processing_warnings": ["string"]
}
]]></artwork>
          </section>
          <section anchor="extensions-object">
            <name>Extensions Object</name>
            <artwork type="json"><![CDATA[
"extensions": {
  "provider_name": {
    // Provider-specific fields preserved during conversion
  }
}
]]></artwork>
          </section>
        </section>
      </section>
    </section>
    <section anchor="provider-integration-guidelines">
      <name>Provider Integration Guidelines</name>
      <section anchor="supported-providers">
        <name>Supported Providers</name>
        <t>The WTF extension supports integration with major transcription providers:</t>
        <ul spacing="normal">
          <li>
            <t><strong>Whisper(TM)</strong>: OpenAI's open-source speech recognition system</t>
          </li>
          <li>
            <t><strong>Deepgram(TM)</strong>: Real-time speech-to-text API</t>
          </li>
          <li>
            <t><strong>AssemblyAI(TM)</strong>: AI-powered transcription and audio intelligence</t>
          </li>
          <li>
            <t><strong>Google Cloud Speech-to-Text(TM)</strong>: Google's speech recognition service</t>
          </li>
          <li>
            <t><strong>Amazon Transcribe(TM)</strong>: AWS speech-to-text service</t>
          </li>
          <li>
            <t><strong>Azure Speech Services(TM)</strong>: Microsoft's speech recognition platform</t>
          </li>
          <li>
            <t><strong>Rev.ai(TM)</strong>: Automated and human transcription services</t>
          </li>
          <li>
            <t><strong>Speechmatics(TM)</strong>: Real-time and batch speech recognition</t>
          </li>
          <li>
            <t><strong>Wav2Vec2(TM)</strong>: Facebook's self-supervised speech recognition model</t>
          </li>
          <li>
            <t><strong>Parakeet(TM)</strong>: NVIDIA's speech recognition toolkit</t>
          </li>
        </ul>
      </section>
      <section anchor="conversion-requirements">
        <name>Conversion Requirements</name>
        <t>When converting from provider-specific formats to WTF:</t>
        <ol spacing="normal" type="1"><li>
            <t><strong>Normalize confidence scores</strong> to <tt>[0.0, 1.0]</tt> range</t>
          </li>
          <li>
            <t><strong>Convert timestamps</strong> to floating-point seconds</t>
          </li>
          <li>
            <t><strong>Standardize language codes</strong> to BCP-47 format</t>
          </li>
          <li>
            <t><strong>Preserve provider-specific features</strong> in extensions field</t>
          </li>
          <li>
            <t><strong>Validate output</strong> against WTF schema requirements</t>
          </li>
        </ol>
      </section>
      <section anchor="provider-specific-mappings">
        <name>Provider-Specific Mappings</name>
        <section anchor="whisper-integration">
          <name>Whisper Integration</name>
          <artwork type="json"><![CDATA[
{
  "extensions": {
    "whisper": {
      "tokens": ["array of token IDs"],
      "temperature": "number",
      "compression_ratio": "number",
      "avg_logprob": "number",
      "no_speech_prob": "number"
    }
  }
}
]]></artwork>
        </section>
        <section anchor="deepgram-integration">
          <name>Deepgram Integration</name>
          <artwork type="json"><![CDATA[
{
  "extensions": {
    "deepgram": {
      "utterances": ["array of utterance objects"],
      "paragraphs": ["array of paragraph objects"],
      "search_terms": ["array of detected search terms"]
    }
  }
}
]]></artwork>
        </section>
      </section>
    </section>
    <section anchor="quality-and-confidence-metrics">
      <name>Quality and Confidence Metrics</name>
      <section anchor="confidence-score-normalization">
        <name>Confidence Score Normalization</name>
        <t>All confidence scores MUST be normalized to the <tt>[0.0, 1.0]</tt> range:</t>
        <ul spacing="normal">
          <li>
            <t><strong>1.0</strong>: Highest confidence (perfect recognition)</t>
          </li>
          <li>
            <t><strong>0.9-1.0</strong>: High confidence</t>
          </li>
          <li>
            <t><strong>0.7-0.9</strong>: Medium confidence</t>
          </li>
          <li>
            <t><strong>0.5-0.7</strong>: Low confidence</t>
          </li>
          <li>
            <t><strong>0.0-0.5</strong>: Very low confidence</t>
          </li>
        </ul>
        <t>Provider-specific scales are converted during import:</t>
        <ul spacing="normal">
          <li>
            <t>Percentage (0-100) -&gt; divide by 100</t>
          </li>
          <li>
            <t>Log probability -&gt; exponential transformation</t>
          </li>
          <li>
            <t>Custom scales -&gt; linear normalization</t>
          </li>
        </ul>
      </section>
      <section anchor="quality-metrics">
        <name>Quality Metrics</name>
        <t>The quality object provides assessment metrics:</t>
        <ul spacing="normal">
          <li>
            <t><strong>audio_quality</strong>: Categorical assessment (high/medium/low)</t>
          </li>
          <li>
            <t><strong>background_noise</strong>: Noise level [0.0-1.0]</t>
          </li>
          <li>
            <t><strong>multiple_speakers</strong>: Boolean indicator of multi-speaker content</t>
          </li>
          <li>
            <t><strong>overlapping_speech</strong>: Boolean indicator of speaker overlap</t>
          </li>
          <li>
            <t><strong>silence_ratio</strong>: Percentage of audio that is silence</t>
          </li>
          <li>
            <t><strong>average_confidence</strong>: Mean confidence across all words/segments</t>
          </li>
          <li>
            <t><strong>low_confidence_words</strong>: Count of words below 0.5 confidence</t>
          </li>
          <li>
            <t><strong>processing_warnings</strong>: Array of processing issues or notices</t>
          </li>
        </ul>
      </section>
    </section>
    <section anchor="security-considerations">
      <name>Security Considerations</name>
      <section anchor="data-privacy">
        <name>Data Privacy</name>
        <t>Transcription data often contains sensitive personal information. Implementations SHOULD:</t>
        <ul spacing="normal">
          <li>
            <t>Apply appropriate access controls to WTF transcription attachments</t>
          </li>
          <li>
            <t>Consider encryption requirements for transcription data at rest and in transit</t>
          </li>
          <li>
            <t>Implement data retention policies consistent with privacy regulations</t>
          </li>
          <li>
            <t>Provide mechanisms for transcription data redaction or anonymization</t>
          </li>
        </ul>
      </section>
      <section anchor="provider-specific-security">
        <name>Provider-Specific Security</name>
        <t>When integrating with external transcription providers:</t>
        <ul spacing="normal">
          <li>
            <t>Validate provider credentials and API security</t>
          </li>
          <li>
            <t>Implement secure communication channels (TLS 1.2 or higher)</t>
          </li>
          <li>
            <t>Consider data residency requirements for audio processing</t>
          </li>
          <li>
            <t>Audit provider data handling practices and compliance certifications</t>
          </li>
        </ul>
      </section>
      <section anchor="integrity-protection">
        <name>Integrity Protection</name>
        <t>WTF transcription attachments SHOULD be integrity protected using vCon signing mechanisms as defined in <xref target="I-D.draft-ietf-vcon-core-00"/> to prevent unauthorized modification of transcription data.</t>
      </section>
      <section anchor="temporal-validation">
        <name>Temporal Validation</name>
        <t>Implementations SHOULD validate that transcription timestamps are consistent with the associated dialog timing information to detect potential tampering or synchronization issues.</t>
      </section>
    </section>
    <section anchor="iana-considerations">
      <name>IANA Considerations</name>
      <section anchor="vcon-extensions-names-registry">
        <name>vCon Extensions Names Registry</name>
        <t>This document requests IANA to register the following extension in the vCon Extensions Names Registry established by <xref target="I-D.draft-ietf-vcon-core-00"/>:</t>
        <ul spacing="normal">
          <li>
            <t><strong>Extension Name</strong>: wtf_transcription</t>
          </li>
          <li>
            <t><strong>Extension Description</strong>: World Transcription Format for standardized speech-to-text representation with multi-provider support</t>
          </li>
          <li>
            <t><strong>Change Controller</strong>: IESG</t>
          </li>
          <li>
            <t><strong>Specification Document</strong>: This document</t>
          </li>
        </ul>
      </section>
      <section anchor="wtf-attachment-type-values-registry">
        <name>WTF Attachment Type Values Registry</name>
        <t>This document requests IANA to establish a new registry for WTF attachment type values with the following initial registration:</t>
        <ul spacing="normal">
          <li>
            <t><strong>Type Value</strong>: wtf_transcription</t>
          </li>
          <li>
            <t><strong>Description</strong>: Structured transcription records using World Transcription Format</t>
          </li>
          <li>
            <t><strong>Change Controller</strong>: IESG</t>
          </li>
          <li>
            <t><strong>Specification Document</strong>: This document
Registration Template:
<strong>Type Value</strong>: The string value used as the attachment type identifier
<strong>Description</strong>: Brief description of the attachment type and its purpose
<strong>Change Controller</strong>: For Standards Track RFCs, list "IESG". For others, give the name of the responsible party.
<strong>Specification Document(s)</strong>: Reference to defining documents with URIs where available</t>
          </li>
        </ul>
      </section>
      <section anchor="wtf-provider-registry">
        <name>WTF Provider Registry</name>
        <t>This document requests IANA to establish a new registry for WTF transcription providers with initial registrations for supported providers:</t>
        <ul spacing="normal">
          <li>
            <t><strong>Provider Name</strong>: whisper</t>
          </li>
          <li>
            <t><strong>Description</strong>: OpenAI Whisper(TM) speech recognition system</t>
          </li>
          <li>
            <t><strong>Change Controller</strong>: IESG</t>
          </li>
          <li>
            <t><strong>Specification Document</strong>: This document
(Additional provider registrations would be added for each supported provider)</t>
          </li>
        </ul>
      </section>
    </section>
    <section anchor="examples">
      <name>Examples</name>
      <section anchor="basic-two-party-call-transcription">
        <name>Basic Two-Party Call Transcription</name>
        <artwork type="json"><![CDATA[
{
  "uuid": "01928e10-193e-8231-b9a2-279e0d16bc46",
  "vcon": "0.0.2",
  "extensions": ["wtf_transcription"],
  "created_at": "2025-01-02T12:00:00Z",
  "parties": [
    {
      "tel": "+1-555-123-4567",
      "name": "Alice"
    },
    {
      "tel": "+1-555-987-6543",
      "name": "Bob"
    }
  ],
  "dialog": [
    {
      "type": "recording",
      "start": "2025-01-02T12:15:30Z",
      "duration": 65.2,
      "parties": [0, 1],
      "mediatype": "audio/wav",
      "filename": "call-recording.wav"
    }
  ],
  "attachments": [
    {
      "type": "wtf_transcription",
      "start": "2025-01-02T12:16:35Z",
      "dialog": 0,
      "encoding": "json",
      "body": {
        "transcript": {
          "text": "Hello, this is Alice from customer service. " +
                  "How can I help you today? Hi Alice, I'm having " +
                  "trouble with my account. Can you help me reset " +
                  "my password?",
          "language": "en-US",
          "duration": 65.2,
          "confidence": 0.92
        },
        "segments": [
          {
            "id": 0,
            "start": 0.5,
            "end": 4.8,
            "text": "Hello, this is Alice from customer service. " +
                    "How can I help you today?",
            "confidence": 0.95,
            "speaker": 0,
            "words": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
          },
          {
            "id": 1,
            "start": 5.2,
            "end": 9.1,
            "text": "Hi Alice, I'm having trouble with my account. " +
                    "Can you help me reset my password?",
            "confidence": 0.88,
            "speaker": 1,
            "words": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
                      30, 31]
          }
        ],
        "words": [
          {
            "id": 0,
            "start": 0.5,
            "end": 0.8,
            "text": "Hello",
            "confidence": 0.98,
            "speaker": 0,
            "is_punctuation": false
          },
          {
            "id": 1,
            "start": 0.9,
            "end": 1.1,
            "text": ",",
            "confidence": 0.95,
            "speaker": 0,
            "is_punctuation": true
          }
          // Additional words...
        ],
        "speakers": {
          "0": {
            "id": 0,
            "label": "Alice (Customer Service)",
            "segments": [0],
            "total_time": 4.3,
            "confidence": 0.95
          },
          "1": {
            "id": 1,
            "label": "Bob (Customer)",
            "segments": [1],
            "total_time": 3.9,
            "confidence": 0.88
          }
        },
        "metadata": {
          "created_at": "2025-01-02T12:15:30Z",
          "processed_at": "2025-01-02T12:16:35Z",
          "provider": "deepgram",
          "model": "nova-2",
          "processing_time": 12.5,
          "audio": {
            "duration": 65.2,
            "sample_rate": 8000,
            "channels": 1,
            "format": "wav",
            "bitrate": 128
          },
          "options": {
            "punctuate": true,
            "diarize": true,
            "language": "en"
          }
        },
        "quality": {
          "audio_quality": "high",
          "background_noise": 0.1,
          "multiple_speakers": true,
          "overlapping_speech": false,
          "silence_ratio": 0.15,
          "average_confidence": 0.92,
          "low_confidence_words": 0,
          "processing_warnings": []
        },
        "extensions": {
          "deepgram": {
            "utterances": [
              {
                "start": 0.5,
                "end": 4.8,
                "confidence": 0.95,
                "channel": 0,
                "transcript": "Hello, this is Alice from customer service. " +
                              "How can I help you today?"
              }
            ]
          }
        }
      }
    }
  ]
}
]]></artwork>
      </section>
      <section anchor="multi-provider-transcription-comparison">
        <name>Multi-Provider Transcription Comparison</name>
        <artwork type="json"><![CDATA[
{
  "attachments": [
    {
      "type": "wtf_transcription",
      "dialog": 0,
      "encoding": "json",
      "body": {
        "transcript": {
          "text": "The quick brown fox jumps over the lazy dog.",
          "language": "en-US",
          "duration": 3.5,
          "confidence": 0.96
        },
        "segments": [
          {
            "id": 0,
            "start": 0.0,
            "end": 3.5,
            "text": "The quick brown fox jumps over the lazy dog.",
            "confidence": 0.96,
            "speaker": 0
          }
        ],
        "metadata": {
          "created_at": "2025-01-02T12:00:00Z",
          "processed_at": "2025-01-02T12:00:15Z",
          "provider": "whisper",
          "model": "whisper-large-v3",
          "processing_time": 15.2
        },
        "extensions": {
          "whisper": {
            "temperature": 0.0,
            "compression_ratio": 2.1,
            "avg_logprob": -0.25,
            "no_speech_prob": 0.01
          }
        }
      }
    },
    {
      "type": "wtf_transcription",
      "dialog": 0,
      "encoding": "json",
      "body": {
        "transcript": {
          "text": "The quick brown fox jumps over the lazy dog.",
          "language": "en-US",
          "duration": 3.5,
          "confidence": 0.94
        },
        "segments": [
          {
            "id": 0,
            "start": 0.0,
            "end": 3.5,
            "text": "The quick brown fox jumps over the lazy dog.",
            "confidence": 0.94,
            "speaker": 0
          }
        ],
        "metadata": {
          "created_at": "2025-01-02T12:00:00Z",
          "processed_at": "2025-01-02T12:00:08Z",
          "provider": "deepgram",
          "model": "nova-2",
          "processing_time": 8.1
        },
        "extensions": {
          "deepgram": {
            "model_info": {
              "name": "nova-2",
              "version": "2024-01-09",
              "uuid": "4d892fb6-7cc1-4e7a-a1b3-1c2e3f4a5b6c"
            }
          }
        }
      }
    }
  ]
}
]]></artwork>
      </section>
    </section>
  </middle>
  <back>
    <references anchor="sec-combined-references">
      <name>References</name>
      <references anchor="sec-normative-references">
        <name>Normative References</name>
        <reference anchor="RFC2119">
          <front>
            <title>Key words for use in RFCs to Indicate Requirement Levels</title>
            <author fullname="S. Bradner" initials="S." surname="Bradner"/>
            <date month="March" year="1997"/>
            <abstract>
              <t>In many standards track documents several words are used to signify the requirements in the specification. These words are often capitalized. This document defines these words as they should be interpreted in IETF documents. This document specifies an Internet Best Current Practices for the Internet Community, and requests discussion and suggestions for improvements.</t>
            </abstract>
          </front>
          <seriesInfo name="BCP" value="14"/>
          <seriesInfo name="RFC" value="2119"/>
          <seriesInfo name="DOI" value="10.17487/RFC2119"/>
        </reference>
        <reference anchor="RFC8174">
          <front>
            <title>Ambiguity of Uppercase vs Lowercase in RFC 2119 Key Words</title>
            <author fullname="B. Leiba" initials="B." surname="Leiba"/>
            <date month="May" year="2017"/>
            <abstract>
              <t>RFC 2119 specifies common key words that may be used in protocol specifications. This document aims to reduce the ambiguity by clarifying that only UPPERCASE usage of the key words have the defined special meanings.</t>
            </abstract>
          </front>
          <seriesInfo name="BCP" value="14"/>
          <seriesInfo name="RFC" value="8174"/>
          <seriesInfo name="DOI" value="10.17487/RFC8174"/>
        </reference>
        <reference anchor="RFC3339" target="https://www.rfc-editor.org/rfc/rfc3339.html">
          <front>
            <title>Date and Time on the Internet: Timestamps</title>
            <author initials="G." surname="Klyne" fullname="G. Klyne">
              <organization/>
            </author>
            <date year="2002" month="July"/>
          </front>
        </reference>
        <reference anchor="I-D.draft-ietf-vcon-core-00" target="I-D.draft-ietf-vcon-core-00">
          <front>
            <title>Virtualized Conversation (vCon) Container</title>
            <author initials="D." surname="Petrie" fullname="Daniel Petrie">
              <organization>SIPez LLC</organization>
            </author>
            <date year="2025" month="March"/>
          </front>
          <seriesInfo name="Internet-Draft" value="draft-ietf-vcon-core-00"/>
        </reference>
        <reference anchor="RFC8949" target="https://www.rfc-editor.org/rfc/rfc8949.html">
          <front>
            <title>Concise Binary Object Representation (CBOR)</title>
            <author initials="C." surname="Bormann" fullname="C. Bormann">
              <organization/>
            </author>
            <date year="2020" month="December"/>
          </front>
        </reference>
      </references>
      <references anchor="sec-informative-references">
        <name>Informative References</name>
        <reference anchor="I-D.draft-ietf-vcon-overview" target="I-D.draft-ietf-vcon-overview-00">
          <front>
            <title>The vCon - Conversation Data Container - Overview</title>
            <author initials="T." surname="McCarthy-Howe" fullname="Thomas McCarthy-Howe">
              <organization>Strolid</organization>
            </author>
            <date year="2025" month="July"/>
          </front>
          <seriesInfo name="Internet-Draft" value="draft-ietf-vcon-overview-00"/>
        </reference>
        <reference anchor="BCP47" target="https://www.rfc-editor.org/rfc/rfc5646.html">
          <front>
            <title>Tags for Identifying Languages</title>
            <author initials="A." surname="Phillips" fullname="A. Phillips">
              <organization/>
            </author>
            <date year="2009" month="September"/>
          </front>
        </reference>
        <reference anchor="WHISPER" target="https://openai.com/research/whisper">
          <front>
            <title>Whisper: Robust Speech Recognition via Large-Scale Weak Supervision</title>
            <author initials="A." surname="Radford" fullname="A. Radford">
              <organization/>
            </author>
            <author initials="J. W." surname="Kim" fullname="J. W. Kim">
              <organization/>
            </author>
            <author initials="T." surname="Xu" fullname="T. Xu">
              <organization/>
            </author>
            <author initials="G." surname="Brockman" fullname="G. Brockman">
              <organization/>
            </author>
            <author initials="C." surname="McLeavey" fullname="C. McLeavey">
              <organization/>
            </author>
            <author initials="I." surname="Sutskever" fullname="I. Sutskever">
              <organization/>
            </author>
            <date year="2022" month="September"/>
          </front>
        </reference>
      </references>
    </references>
    <?line 803?>

<section numbered="false" anchor="acknowledgements">
      <name>Acknowledgements</name>
      <ul spacing="normal">
        <li>
          <t>Appreciation to the transcription provider community for their input on standardization requirements.</t>
        </li>
        <li>
          <t>Thanks to the vCon working group for their feedback and guidance on extension design patterns.</t>
        </li>
      </ul>
    </section>
    <section numbered="false" anchor="trademark-notice">
      <name>Trademark Notice</name>
      <t>All trademarks mentioned in this document are the property of their respective owners. The use of these trademarks does not imply endorsement by the IETF or the authors of this document. The following trademarks are referenced:</t>
      <ul spacing="normal">
        <li>
          <t>Whisper(TM) is a trademark of OpenAI, Inc.</t>
        </li>
        <li>
          <t>Deepgram(TM) is a trademark of Deepgram, Inc.</t>
        </li>
        <li>
          <t>AssemblyAI(TM) is a trademark of AssemblyAI, Inc.</t>
        </li>
        <li>
          <t>Google Cloud Speech-to-Text(TM) is a trademark of Google LLC.</t>
        </li>
        <li>
          <t>Amazon Transcribe(TM) is a trademark of Amazon.com, Inc.</t>
        </li>
        <li>
          <t>Azure Speech Services(TM) is a trademark of Microsoft Corporation.</t>
        </li>
        <li>
          <t>Rev.ai(TM) is a trademark of Rev.com, Inc.</t>
        </li>
        <li>
          <t>Speechmatics(TM) is a trademark of Speechmatics Limited.</t>
        </li>
        <li>
          <t>Wav2Vec2(TM) is a trademark of Meta Platforms, Inc.</t>
        </li>
        <li>
          <t>Parakeet(TM) is a trademark of NVIDIA Corporation.</t>
        </li>
      </ul>
    </section>
  </back>
  <!-- ##markdown-source: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-->

</rfc>
